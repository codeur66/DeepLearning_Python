


************************Error*************************************
ValueError: Input 0 of layer dense is incompatible with the layer:
expected axis -1 of input shape to have value 1000000 but received
input with shape [None, 10000].
******************************************************************
The investigation to solution:
#1# use of run_eagerly=True) in compile () to debug what happens during fit(),  set to None when fixed the bug to regain the speed.
#2# check the summary() print.

Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
embedding (Embedding)        (None, 10000, 100)        1000000
_________________________________________________________________
flatten (Flatten)            (None, 1000000)           0           <--- here seems a multiplication of (None x 10000 x 100)
_________________________________________________________________  the error says "Input 0 of layer dense is incompatible..."
dense (Dense)                (None, 32)                32000032    the layer 0 is the Dense, it took weights of shape (10000 x 100)
_________________________________________________________________  but embedding gives 10000x100 so we check the embedding layer
dense_1 (Dense)              (None, 1)                 33          in model.add(Embedding(max_words, embeddings_dimension, input_length=max_len))
=================================================================  The Flatten does not affect the dimensions only flattens whatever it takes.

#3# print the shapes of the data and structures and variables related to the network.

x_train, y_train, x_val, y_val ;  (200, 100) (200,) (10000, 100) (10000,) <---- same dimension
Found 100 coefficients. <---- same dimension
Found 400000 word vectors.<---- same dimension
Found 88582 unique tokens.<---- same dimension
embedding_matrix shape :  (10000, 100)    <---- same dimension
Found 100 coefficients. <---- same dimension
Found 400000 word vectors. <----same dimension


#4# plot
sudo apt install graphviz # for keras.utils.plot_model
pip install pydot  # for keras.utils.plot_model

kears.utils.plot_model(model, show_shapes=True)



#Fixed Error#

Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
embedding (Embedding)        (None, 100, 100)          1000000
_________________________________________________________________
flatten (Flatten)            (None, 10000)             0
_________________________________________________________________
dense (Dense)                (None, 32)                320032
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 33
=================================================================
Total params: 1,320,065
Trainable params: 1,320,065
Non-trainable params: 0
_________________________________________________________________



************************Error*************************************
Object cannot serialized to JSON
******************************************************************

In configuration_infrastructure where serialization takes place:
HelperObject returns a class type of HelperObject
instead of a 'dict'
params = json.loads(json.dumps(cfg), object_hook=HelperObject)

#1#
Remove from the JSON file the Keras classes you wanted to serialize

#2#
params = json.loads(json.dumps(cfg), default = lambda x: x.__dict__, object_hook=HelperObject)
converts everything to dict but the build-in classes of Keras do not serialized this way.



********************Error*****************************************
x_train, y_train, x_val, y_val, embeddings_matrix = md.load_data()
TypeError: 'NoneType' object is not iterable
*******************************************************************

#Fixed Error#
forgot to delete the global variables
HDFS_INTERNAL_DATA_FILENAME
HDFS_EXTERNAL_DATA_FILENAME
re declared with wrong path
overwriting the configurtion.py



********************Error*****************************************
AttributeError: 'HelperObject' object has no attribute 'HDFS_EXTERNAL_DATA_FILENAME'
*******************************************************************
#Fixed Error#
the HDFS_EXTERNAL_DATA_FILENAME passed through the wrong JSON parent object.
config.external_data_sources.HDFS_EXTERNAL_DATA_FILENAME
instead of
config.data_sources.HDFS_EXTERNAL_DATA_FILENAME
